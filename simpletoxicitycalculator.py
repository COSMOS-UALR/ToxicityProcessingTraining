# -*- coding: utf-8 -*-
"""SimpleToxicityCalculator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19OEaGHqjmaJnWZuyxXR6eqIly2sM-p9V

##  Installing Libraries and Packages
"""

!pip install detoxify

from detoxify import Detoxify
from tqdm import tqdm
import torch
import os
import pandas as pd
import math

"""## Function to Import Data files in a Folder"""

def import_data(import_folder:str):
    """Walks through the import folder and yields a list of dicts for each file.
    Will only process json, csv, xlsx and txt files.

    Args:
        import_folder (str, optional): The folder holding the data. Defaults to "Import".

    Yields:
        [list]: list of dictionaries, representing each row from the file
    """
    for _, _, fnames in os.walk(import_folder):
        with tqdm(total=len([x for x in fnames if '.json' in x or '.xlsx' in x or '.csv' in x])) as pbar:
            for fname in fnames:
                pbar.set_description(fname.replace('.json',''))
                if '.json' in fname:
                    df = pd.read_json(f"{import_folder}/{fname}")
                    data = df.T.to_dict().values()
                    yield data, fname
                elif '.xlsx' in fname:
                    df = pd.read_excel(f"{import_folder}/{fname}", engine='openpyxl')
                    data = df.T.to_dict().values()
                    del df
                    yield data, fname
                elif '.csv' in fname:
                    df = pd.read_csv(f"{import_folder}/{fname}")
                    data = df.T.to_dict().values()
                    del df
                    yield data, fname
                elif '.txt' in fname:
                    print("Text FileName is ", f"{import_folder}/{fname}")
                    df = pd.read_csv(f"{import_folder}/{fname}", names=['text'], sep="\n", header=None)
                    data = df.T.to_dict().values()
                    del df
                    # print("Dictionary  ", data)
                    yield data, fname
                else:
                    print("Not supported Format ", f"{import_folder}/{fname}")
                    pass
                pbar.update(1)

"""## Function to Clean the Text Column - with `@` and `.com`"""

def clean_text(text:str):
    if type(text) == float:
        return None
    if text and ''.join(text.split()):
        if type(text) == bytes: #Decoding byte strings
            text = text.decode('utf-8')
        #Removing emails + ***.com urls
        text = ' '.join([item for item in text.split() if '@' not in item and '.com' not in item])
        text = ' '.join(text.split()) #removing all multiple spaces
        if text: return text
    return None

"""## Function to Break the List of Data with Items per Chunk"""

def chunk_lst(lst:list, items_per_chunk:int):
    """Breaks a list into chunks
    Args:
        lst ([list]): List to chunk
        items_per_chunk ([int]): Number of items per list
    Yields:
        [list]: a chunk of lst, with size 'items_per_chunk'
    """
    for i in range(0, len(lst), items_per_chunk):
        yield lst[i:i + items_per_chunk]

"""## Function to Calculate Detoxicity of Text"""

from detoxify import Detoxify
results = Detoxify('unbiased').predict(['Pass it on.','Please do not skip any regulatory steps or licensing requirements'])
print("results Dictionary ", results)
print("results only Toxicity ", results.get('toxicity'))

def get_scores(text, model):
    with torch.no_grad():
        print("Text Size - ", len(text))
        if type(text) == str:
            result = model.predict(text)
            return result.get('toxicity')
        elif type(text) == list:
            results = []
            chunk_size = 100
            for l in tqdm(chunk_lst(text, chunk_size), desc="Processing Scores", total=math.ceil(len(text)/chunk_size)):
                un_formated_results = model.predict(l)
                print("un_formated_results Dictionary ", un_formated_results)
                results += un_formated_results.get('toxicity')
        return results

"""## Function to Process data and write the Results. """

def process_data(data:list, text_columns:list, model:Detoxify) ->list:
    """Computes the toxicity score for a batch of data.
    The toxicity score will be added into each dictionary as 'text_column + "_toxicity"'

    Args:
        data (list): list of dictionaries
        text_column (list): the id of the text column you want to compute
        model (Detoxify): the detoxify model you wish to use

    Returns:
        list: list of dictionaries
    """
    #Cleaning text
    for text_column in text_columns:
        texts = []
        for row in data:
            cleaned_text = clean_text(row[text_column])
            text =  cleaned_text if cleaned_text else ''
            texts.append(text)
        results = get_scores(texts, model)
        print("results length: ", len(results))
    return results

"""## Input Parameters for the SimpleToxicity Calcultor """

model = Detoxify("unbiased", device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")) #device='cude'
process_sentiment = True
#Set output format
select_output_format = 3
output_formats = ['json', 'csv', 'xlsx']
#Text column name
text_columns = ["text"]

"""## Run the code 
1.   Input - import_folder -  The folder holding the data. 
2.   Output - filename_toxicity.csv 


"""

def process_file_toxicity(folder_path: str):
  for data, fname in import_data(folder_path):
      updated_data = process_data(data, text_columns, model)
      print("List Dictionary ", updated_data, fname)
      df = pd.DataFrame(updated_data)
      # Write toxicity score to csv file appending filename + '_toxicity'
      save_fname = fname.split('.')[0]
      df.to_csv(f"{folder_path}/{save_fname}_toxicity.csv")


process_file_toxicity("sample_data/sample")

"""## Save toxicity Values to CSV files"""

save_fname = fname.split('.')[0]
df.to_csv(f"{save_fname}_toxicity.csv")

## cleantext() 
len(updated_data)